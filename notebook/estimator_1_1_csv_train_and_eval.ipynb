{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目标:\n",
    "1. 使用CSV文件作为数据的来源，采用train_and_eval(keras自带在train当中)进行训练，\n",
    "2. 进而使用数据验证模型，测试数据测试模型，然后运行一下预测；最后导出模型供使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import shutil\n",
    "import math\n",
    "from datetime import datetime\n",
    "import multiprocessing\n",
    "from tensorflow.python.feature_column import feature_column\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'reg-model-02'\n",
    "\n",
    "TRAIN_DATA_FILES_PATTERN = 'data/train-*.csv'\n",
    "VALID_DATA_FILES_PATTERN = 'data/valid-*.csv'\n",
    "TEST_DATA_FILES_PATTERN = 'data/test-*.csv'\n",
    "\n",
    "RESUME_TRAINING = False\n",
    "PROCESS_FEATURES = True\n",
    "EXTEND_FEATURE_COLUMNS = True\n",
    "MULTI_THREADING = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本步骤\n",
    "1. 定义数据集的元数据(常量到处使用)\n",
    "2. 定义读取CSV的输入函数及其解析(ETL)\n",
    "3. 定义特征列\n",
    "4. 定义估计器的创建函数\n",
    "5. 运行试验，包括运行方案的定义\n",
    "6. 运行模型的评估\n",
    "7. 执行预测和部署已存的模型\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 定义数据集元数据\n",
    "- CSV的头和默认值\n",
    "- 数据和类别特征名称\n",
    "- 目标列名称\n",
    "- 无用列名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADER = ['key','x','y','alpha','beta','target']\n",
    "HEADER_DEFAULTS = [[0], [0.0], [0.0], ['NA'], ['NA'], [0.0]]\n",
    "NUMERIC_FEATURE_NAMES = ['x', 'y']  \n",
    "CATEGORICAL_FEATURE_NAMES_WITH_VOCABULARY = {'alpha':['ax01', 'ax02'], 'beta':['bx01', 'bx02']}\n",
    "CATEGORICAL_FEATURE_NAMES = list(CATEGORICAL_FEATURE_NAMES_WITH_VOCABULARY.keys())\n",
    "FEATURE_NAMES = NUMERIC_FEATURE_NAMES + CATEGORICAL_FEATURE_NAMES\n",
    "TARGET_NAME = 'target'\n",
    "UNUSED_FEATURE_NAMES = list(set(HEADER) - set(FEATURE_NAMES) - {TARGET_NAME})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 定义数据数据输入函数\n",
    "- 输入文件名称模式\n",
    "- 使用dataset读入数据\n",
    "- 解析特征\n",
    "- 使用处理\n",
    "- 返回(特征，目标)张量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature read from CSV: ['x', 'y', 'alpha', 'beta', 'x_2', 'y_2', 'xy', 'dist_xy']\n",
      "Target read from CSV: Tensor(\"IteratorGetNext_15:8\", shape=(?,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def process_features(features):\n",
    "    \"\"\"输入数据时张量，采用tf-api，特征名-张量的字典\"\"\"\n",
    "    features['x_2']=tf.square(features['x'])\n",
    "    features[\"x_2\"] = tf.square(features['x'])\n",
    "    features[\"y_2\"] = tf.square(features['y'])\n",
    "    features[\"xy\"] = tf.multiply(features['x'], features['y']) # features['x'] * features['y']\n",
    "    features['dist_xy'] =  tf.sqrt(tf.squared_difference(features['x'],features['y']))\n",
    "    return features\n",
    "\n",
    "def parse_csv_row(csv_row):\n",
    "    \"\"\"返回特征字典-目标元组，供dataset\"\"\"\n",
    "    columns=tf.decode_csv(csv_row,record_defaults=HEADER_DEFAULTS) #按顺序解析\n",
    "    features=dict(zip(HEADER,columns))\n",
    "    for col in UNUSED_FEATURE_NAMES:\n",
    "        features.pop(col)\n",
    "    target= features.pop(TARGET_NAME)\n",
    "    return features,target\n",
    "    \n",
    "    \n",
    "def csv_input_fn(files_name_pattern, mode=tf.estimator.ModeKeys.EVAL, \n",
    "                 skip_header_lines=0,num_epochs=None,batch_size=200):\n",
    "    \n",
    "    shuffle=True if mode==tf.estimator.ModeKeys.TRAIN else False\n",
    "    input_file_names=tf.matching_files(files_name_pattern)\n",
    "    dataset = tf.data.TextLineDataset(input_file_names)\n",
    "    dataset = dataset.skip(skip_header_lines)\n",
    "    dataset = dataset.map(parse_csv_row)\n",
    "    if PROCESS_FEATURES:\n",
    "        dataset = dataset.map(lambda features, target: (process_features(features), target))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=2 * batch_size + 1)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    features,target =iterator.get_next()\n",
    "    return features,target\n",
    "# 读取文件的输出列和特征列feature_columns输入列不容易对上，这个地方最好共享一份数据，而不是人工重写核对\n",
    "features, target = csv_input_fn(files_name_pattern=\"\")\n",
    "print(\"Feature read from CSV: {}\".format(list(features.keys())))\n",
    "print(\"Target read from CSV: {}\".format(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.定义特征列\n",
    "假设数值列规范化了或者同尺度，否则使用特征列构造器，\n",
    "传递normlizer_fn及其normlisation params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Columns: {'x': _NumericColumn(key='x', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), 'y': _NumericColumn(key='y', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), 'x_2': _NumericColumn(key='x_2', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), 'y_2': _NumericColumn(key='y_2', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), 'xy': _NumericColumn(key='xy', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), 'dist_xy': _NumericColumn(key='dist_xy', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), 'alpha': _VocabularyListCategoricalColumn(key='alpha', vocabulary_list=('ax01', 'ax02'), dtype=tf.string, default_value=-1, num_oov_buckets=0), 'beta': _VocabularyListCategoricalColumn(key='beta', vocabulary_list=('bx01', 'bx02'), dtype=tf.string, default_value=-1, num_oov_buckets=0), 'alpha_X_beta': _CrossedColumn(keys=(_VocabularyListCategoricalColumn(key='alpha', vocabulary_list=('ax01', 'ax02'), dtype=tf.string, default_value=-1, num_oov_buckets=0), _VocabularyListCategoricalColumn(key='beta', vocabulary_list=('bx01', 'bx02'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), hash_bucket_size=4, hash_key=None)}\n"
     ]
    }
   ],
   "source": [
    "def extend_feature_columns(feature_columns):\n",
    "    \"\"\"添加交叉列\"\"\"\n",
    "    feature_columns['alpha_X_beta'] = tf.feature_column.crossed_column([feature_columns['alpha'], feature_columns['beta']], 4)\n",
    "    return feature_columns\n",
    "\n",
    "def get_feature_columns():\n",
    "    CONSTRUCTED_NUMERIC_FEATURES_NAMES = ['x_2', 'y_2', 'xy', 'dist_xy']\n",
    "    all_numeric_feature_names = NUMERIC_FEATURE_NAMES.copy() \n",
    "    if PROCESS_FEATURES: # 进一步选择输入的列\n",
    "        all_numeric_feature_names += CONSTRUCTED_NUMERIC_FEATURES_NAMES\n",
    "    numeric_columns = {feature_name: tf.feature_column.numeric_column(feature_name)\n",
    "                       for feature_name in all_numeric_feature_names}\n",
    "    categorical_column_with_vocabulary = \\\n",
    "        {item[0]: tf.feature_column.categorical_column_with_vocabulary_list(item[0], item[1])\n",
    "         for item in CATEGORICAL_FEATURE_NAMES_WITH_VOCABULARY.items()}\n",
    "    # 将准备好的列全出整起来\n",
    "    feature_columns = {}\n",
    "    if numeric_columns is not None:\n",
    "        feature_columns.update(numeric_columns)\n",
    "    if categorical_column_with_vocabulary is not None:\n",
    "        feature_columns.update(categorical_column_with_vocabulary)\n",
    "    # 函数和常量一样是个模块全局对象没有必要传递，直接引用就好\n",
    "    if EXTEND_FEATURE_COLUMNS:\n",
    "        feature_columns = extend_feature_columns(feature_columns)\n",
    "    return feature_columns\n",
    "\n",
    "feature_columns = get_feature_columns()\n",
    "print(\"Feature Columns: {}\".format(feature_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['x', 'y', 'x_2', 'y_2', 'xy', 'dist_xy', 'alpha', 'beta', 'alpha_X_beta'])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "y\n",
      "x_2\n",
      "y_2\n",
      "xy\n",
      "dist_xy\n",
      "alpha\n",
      "beta\n"
     ]
    }
   ],
   "source": [
    "for i in dense_columns+categorical_columns:\n",
    "    print(i.key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 定义估计器创建函数\n",
    "- 从特征列中获取数值特征列\n",
    "- 将类型特征列转化成\n",
    "- 使用dense + indicator feature columns + params创建估计器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_estimator(run_config,hparams):\n",
    "    feature_columns = list(get_feature_columns().values())\n",
    "    dense_columns=list(filter(lambda col:isinstance(col,feature_column._NumericColumn),feature_columns))\n",
    "    categorical_columns=list(filter(lambda col:isinstance(col,(feature_column._VocabularyListCategoricalColumn,feature_column._BucketizedColumn)),\n",
    "                                  feature_columns))\n",
    "    indicator_columns = list(map(lambda column: tf.feature_column.indicator_column(column),categorical_columns))\n",
    "    \n",
    "    estimator=tf.estimator.DNNRegressor(feature_columns=dense_columns+indicator_columns,\n",
    "                                       hidden_units=hparams.hidden_units,optimizer=tf.train.AdadeltaOptimizer(),\n",
    "                                       activation_fn=tf.nn.elu,dropout= hparams.dropout_prob,config= run_config)\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_NumericColumn(key='x', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='y', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='x_2', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='y_2', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='xy', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='dist_xy', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _IndicatorColumn(categorical_column=_VocabularyListCategoricalColumn(key='alpha', vocabulary_list=('ax01', 'ax02'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " _IndicatorColumn(categorical_column=_VocabularyListCategoricalColumn(key='beta', vocabulary_list=('bx01', 'bx02'), dtype=tf.string, default_value=-1, num_oov_buckets=0))]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(get_feature_columns().keys())\n",
    "dense_columns+indicator_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_NumericColumn(key='x', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='y', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='x_2', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='y_2', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='xy', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='dist_xy', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _IndicatorColumn(categorical_column=_VocabularyListCategoricalColumn(key='alpha', vocabulary_list=('ax01', 'ax02'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " _IndicatorColumn(categorical_column=_VocabularyListCategoricalColumn(key='beta', vocabulary_list=('bx01', 'bx02'), dtype=tf.string, default_value=-1, num_oov_buckets=0))]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = list(get_feature_columns().values())\n",
    "dense_columns=list(filter(lambda col:isinstance(col,feature_column._NumericColumn),feature_columns))\n",
    "categorical_columns=list(filter(lambda col:isinstance(col,(feature_column._VocabularyListCategoricalColumn,feature_column._BucketizedColumn)),\n",
    "                                  feature_columns))\n",
    "indicator_columns = list(map(lambda column: tf.feature_column.indicator_column(column),categorical_columns))\n",
    "\n",
    "dense_columns+indicator_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl=dense_columns[0]\n",
    "cl.key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 运行试验\n",
    "- a. 设置运行参数和模型超参数HParam and RunConfig\n",
    "- b. 定义Serving Function\n",
    "- c. 定义一个Early Stopping Monitor (Hook)\n",
    "- d. 定义TrainSpec and EvaluSpec方案\n",
    "\n",
    "进行了这个多定义，现在模块空间有多少对象？函数对象和实例对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 12000\n",
    "NUM_EPOCHS = 1000\n",
    "BATCH_SIZE = 500\n",
    "EVAL_AFTER_SEC = 15\n",
    "TOTAL_STEPS = (TRAIN_SIZE/BATCH_SIZE)*NUM_EPOCHS\n",
    "\n",
    "hparams  = tf.contrib.training.HParams(\n",
    "    num_epochs = 100, \n",
    "    batch_size = 500,\n",
    "    hidden_units=[8, 4],\n",
    "    early_stopping_rounds = 1,\n",
    "    dropout_prob = 0.0)\n",
    "\n",
    "model_dir = 'trained_models/{}'.format(MODEL_NAME)\n",
    "\n",
    "run_config = tf.estimator.RunConfig((\n",
    "    save_checkpoints_steps=480, # to evaluate after each 20 epochs => (12000/500) * 20\n",
    "    tf_random_seed=19830610,\n",
    "    model_dir=model_dir\n",
    ")\n",
    "\n",
    "print(\"Model directory: {}\".format(run_config.model_dir))\n",
    "print(\"Hyper-parameters: {}\".format(hparams))\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_serving_input():\n",
    "    SERVING_HEADER = ['x','y','alpha','beta']\n",
    "    SERVING_HEADER_DEFAULTS = [[0.0], [0.0], ['NA'], ['NA']]\n",
    "    rows_string_tensor = tf.placeholder(dtype=tf.string,shape=[None], name='csv_rows')\n",
    "    receiver_tensor = {'csv_rows': rows_string_tensor}\n",
    "    row_columns = tf.expand_dims(rows_string_tensor, -1) #变成2阶，另一axis来放置特征\n",
    "    columns = tf.decode_csv(row_columns, record_defaults=SERVING_HEADER_DEFAULTS)\n",
    "    features = dict(zip(SERVING_HEADER, columns))\n",
    "    if PROCESS_FEATURES: features = process_features(features)\n",
    "    return tf.estimator.export.ServingInputReceiver(features, receiver_tensor)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStoppingHook(tf.train.SessionRunHook):\n",
    "    def __init__(self, early_stopping_rounds=1):\n",
    "        self._best_loss = None\n",
    "        self._early_stopping_rounds = early_stopping_rounds\n",
    "        self._counter = 0\n",
    "        print(\"*** Early Stopping Hook: - Created\")\n",
    "        print(\"*** Early Stopping Hook:: Early Stopping Rounds: {}\".format(self._early_stopping_rounds))\n",
    "    def before_run(self, run_context):  # 调度程序返回给方法的对象\n",
    "        graph = run_context.session.graph\n",
    "        loss_tensor = graph.get_collection(tf.GraphKeys.LOSSES)[1]\n",
    "        return tf.train.SessionRunArgs(loss_tensor)\n",
    "\n",
    "    def after_run(self, run_context, run_values):\n",
    "        last_loss = run_values.results\n",
    "        print(\"************************\")\n",
    "        print(\"** Evaluation Monitor - Early Stopping **\")\n",
    "        print(\"Early Stopping Hook: Current loss: {}\".format(str(last_loss)))\n",
    "        print(\"Early Stopping Hook: Best loss: {}\".format(str(self._best_loss)))\n",
    "\n",
    "        if self._best_loss is None:\n",
    "            self._best_loss = last_loss\n",
    "        elif last_loss > self._best_loss:\n",
    "            self._counter += 1\n",
    "            print(\"Early Stopping Hook: No improvment! Counter: {}\".format(self._counter))\n",
    "            if self._counter == self._early_stopping_rounds:\n",
    "                run_context.request_stop()\n",
    "                print(\"Early Stopping Hook: Stop Requested: {}\".format(run_context.stop_requested))\n",
    "        else:\n",
    "            self._best_loss = last_loss\n",
    "            self._counter = 0\n",
    "        print(\"************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "train_input_fn=functools.partial(csv_input_fn,\n",
    "                                 files_name_pattern=TRAIN_DATA_FILES_PATTERN,\n",
    "                                 mode=tf.estimator.ModeKeys.TRAIN,\n",
    "                                 num_epochs=hparams.num_epochs,\n",
    "                                 batch_size=hparams.batch_size)\n",
    "\n",
    "valid_input_fn =functools.partial(csv_input_fn,\n",
    "                                  files_name_pattern=VALID_DATA_FILES_PATTERN,\n",
    "                                  mode=tf.estimator.ModeKeys.EVAL,\n",
    "                                  num_epochs=1,\n",
    "                                  batch_size=hparams.batch_size)\n",
    "\n",
    "test_input_fn =functools.partial(csv_input_fn,\n",
    "                                  files_name_pattern=TEST_DATA_FILES_PATTERN,\n",
    "                                  mode=tf.estimator.ModeKeys.EVAL,\n",
    "                                  num_epochs=hparams.num_epochs,\n",
    "                                  batch_size=hparams.batch_size)\n",
    "\n",
    "predict_input_fn =functools.partial(csv_input_fn,\n",
    "                                    files_name_pattern= TEST_DATA_FILES_PATTERN,\n",
    "                                    mode= tf.estimator.ModeKeys.PREDICT,batch_size= 5)\n",
    "\n",
    "\n",
    "train_spec=tf.estimator.TrainSpec(train_input_fn,max_steps=hparams.max_steps,hooks=None)\n",
    "\n",
    "\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(valid_input_fn,\n",
    "                                  steps=None,\n",
    "                                  throttle_secs = EVAL_AFTER_SEC)# evalute after each 15 training seconds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################所使用的对象定义(定义函数即实例化函数对象)完毕，下面开始训练操作####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing previous artifacts...\n",
      "Experiment started at 11:26:37\n",
      ".......................................\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'trained_models/reg-model-02', '_tf_random_seed': 19830610, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000000040547358>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into trained_models/reg-model-02\\model.ckpt.\n",
      "INFO:tensorflow:loss = 157387.39, step = 1\n",
      "INFO:tensorflow:global_step/sec: 47.9616\n",
      "INFO:tensorflow:loss = 156323.75, step = 101 (2.086 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.6524\n",
      "INFO:tensorflow:loss = 160119.33, step = 201 (2.013 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.6842\n",
      "INFO:tensorflow:loss = 155704.75, step = 301 (1.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.05\n",
      "INFO:tensorflow:loss = 151259.14, step = 401 (1.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.6073\n",
      "INFO:tensorflow:loss = 130287.26, step = 501 (1.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.813\n",
      "INFO:tensorflow:loss = 164417.66, step = 601 (1.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.8998\n",
      "INFO:tensorflow:loss = 162643.6, step = 701 (2.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.8906\n",
      "INFO:tensorflow:loss = 162529.23, step = 801 (1.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.8759\n",
      "INFO:tensorflow:loss = 158937.47, step = 901 (2.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.975\n",
      "INFO:tensorflow:loss = 147965.12, step = 1001 (2.000 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.025\n",
      "INFO:tensorflow:loss = 171810.2, step = 1101 (1.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.824\n",
      "INFO:tensorflow:loss = 151172.47, step = 1201 (2.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.9237\n",
      "INFO:tensorflow:loss = 136843.25, step = 1301 (2.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.2367\n",
      "INFO:tensorflow:loss = 154708.03, step = 1401 (2.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.2393\n",
      "INFO:tensorflow:loss = 139694.1, step = 1501 (2.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.3092\n",
      "INFO:tensorflow:loss = 163772.27, step = 1601 (2.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.5786\n",
      "INFO:tensorflow:loss = 172481.52, step = 1701 (2.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.1\n",
      "INFO:tensorflow:loss = 172821.5, step = 1801 (2.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.2367\n",
      "INFO:tensorflow:loss = 166899.72, step = 1901 (2.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.1159\n",
      "INFO:tensorflow:loss = 170790.75, step = 2001 (2.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.8008\n",
      "INFO:tensorflow:loss = 156730.25, step = 2101 (2.009 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.8753\n",
      "INFO:tensorflow:loss = 129257.14, step = 2201 (2.005 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.14\n",
      "INFO:tensorflow:loss = 157881.84, step = 2301 (2.034 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.1642\n",
      "INFO:tensorflow:loss = 161241.16, step = 2401 (2.035 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.1002\n",
      "INFO:tensorflow:loss = 148733.2, step = 2501 (1.995 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.0751\n",
      "INFO:tensorflow:loss = 178166.1, step = 2601 (1.997 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.2513\n",
      "INFO:tensorflow:loss = 145170.86, step = 2701 (2.020 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.4158\n",
      "INFO:tensorflow:loss = 153659.86, step = 2801 (2.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.0196\n",
      "INFO:tensorflow:loss = 157936.05, step = 2901 (2.040 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.2858\n",
      "INFO:tensorflow:loss = 184991.38, step = 3001 (2.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.8011\n",
      "INFO:tensorflow:loss = 137822.39, step = 3101 (2.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.554\n",
      "INFO:tensorflow:loss = 168181.67, step = 3201 (2.019 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.3325\n",
      "INFO:tensorflow:loss = 168000.17, step = 3301 (2.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.8469\n",
      "INFO:tensorflow:loss = 146728.31, step = 3401 (2.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.0307\n",
      "INFO:tensorflow:loss = 134263.11, step = 3501 (2.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.5434\n",
      "INFO:tensorflow:loss = 181617.36, step = 3601 (2.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.2813\n",
      "INFO:tensorflow:loss = 136729.75, step = 3701 (2.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.0367\n",
      "INFO:tensorflow:loss = 143994.42, step = 3801 (2.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.1232\n",
      "INFO:tensorflow:loss = 162088.11, step = 3901 (2.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.3525\n",
      "INFO:tensorflow:loss = 152377.36, step = 4001 (1.986 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.7567\n",
      "INFO:tensorflow:loss = 154867.03, step = 4101 (2.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.8295\n",
      "INFO:tensorflow:loss = 189715.97, step = 4201 (2.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.2367\n",
      "INFO:tensorflow:loss = 162390.75, step = 4301 (2.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.5786\n",
      "INFO:tensorflow:loss = 139044.75, step = 4401 (2.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.4032\n",
      "INFO:tensorflow:loss = 166293.08, step = 4501 (1.983 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.7508\n",
      "INFO:tensorflow:loss = 148525.22, step = 4601 (2.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.7567\n",
      "INFO:tensorflow:loss = 157309.64, step = 4701 (2.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.334\n",
      "INFO:tensorflow:loss = 144022.78, step = 4801 (2.027 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.8256\n",
      "INFO:tensorflow:loss = 152400.02, step = 4901 (2.007 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.168\n",
      "INFO:tensorflow:loss = 167309.36, step = 5001 (2.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.9263\n",
      "INFO:tensorflow:loss = 159320.95, step = 5101 (2.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.8758\n",
      "INFO:tensorflow:loss = 155501.95, step = 5201 (2.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.1254\n",
      "INFO:tensorflow:loss = 154072.0, step = 5301 (2.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.975\n",
      "INFO:tensorflow:loss = 153989.81, step = 5401 (2.001 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.8165\n",
      "INFO:tensorflow:loss = 153541.31, step = 5501 (2.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.9704\n",
      "INFO:tensorflow:loss = 169055.0, step = 5601 (2.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.4966\n",
      "INFO:tensorflow:loss = 179221.97, step = 5701 (2.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.0751\n",
      "INFO:tensorflow:loss = 147895.53, step = 5801 (1.996 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.8647\n",
      "INFO:tensorflow:loss = 135799.23, step = 5901 (1.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 50\n",
      "INFO:tensorflow:loss = 155790.97, step = 6001 (2.000 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.259\n",
      "INFO:tensorflow:loss = 164641.39, step = 6101 (2.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.5737\n",
      "INFO:tensorflow:loss = 156618.4, step = 6201 (2.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.1921\n",
      "INFO:tensorflow:loss = 149623.33, step = 6301 (2.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.505\n",
      "INFO:tensorflow:loss = 141042.36, step = 6401 (2.020 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.5285\n",
      "INFO:tensorflow:loss = 153860.66, step = 6501 (2.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.9956\n",
      "INFO:tensorflow:loss = 168081.34, step = 6601 (2.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.5295\n",
      "INFO:tensorflow:loss = 156505.17, step = 6701 (2.020 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 49.6032\n",
      "INFO:tensorflow:loss = 147670.06, step = 6801 (2.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.0918\n",
      "INFO:tensorflow:loss = 154400.98, step = 6901 (2.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.6032\n",
      "INFO:tensorflow:loss = 152946.77, step = 7001 (2.016 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.975\n",
      "INFO:tensorflow:loss = 137715.98, step = 7101 (2.001 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.0588\n",
      "INFO:tensorflow:loss = 183917.7, step = 7201 (2.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.1464\n",
      "INFO:tensorflow:loss = 156468.45, step = 7301 (2.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.813\n",
      "INFO:tensorflow:loss = 160316.95, step = 7401 (1.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.3778\n",
      "INFO:tensorflow:loss = 165363.77, step = 7501 (1.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.9846\n",
      "INFO:tensorflow:loss = 155529.89, step = 7601 (2.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.4731\n",
      "INFO:tensorflow:loss = 156363.02, step = 7701 (2.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.6329\n",
      "INFO:tensorflow:loss = 177543.92, step = 7801 (1.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.7099\n",
      "INFO:tensorflow:loss = 160316.53, step = 7901 (1.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.226\n",
      "INFO:tensorflow:loss = 153187.48, step = 8001 (1.991 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.2008\n",
      "INFO:tensorflow:loss = 155047.44, step = 8101 (1.993 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.0769\n",
      "INFO:tensorflow:loss = 152168.89, step = 8201 (2.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.3018\n",
      "INFO:tensorflow:loss = 153053.66, step = 8301 (1.988 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.6842\n",
      "INFO:tensorflow:loss = 181480.94, step = 8401 (1.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.5437\n",
      "INFO:tensorflow:loss = 157001.89, step = 8501 (2.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.3525\n",
      "INFO:tensorflow:loss = 172029.39, step = 8601 (2.033 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.216\n",
      "INFO:tensorflow:loss = 154605.52, step = 8701 (2.027 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.5306\n",
      "INFO:tensorflow:loss = 143198.47, step = 8801 (1.980 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.1253\n",
      "INFO:tensorflow:loss = 169364.97, step = 8901 (1.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.8011\n",
      "INFO:tensorflow:loss = 153973.64, step = 9001 (2.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.975\n",
      "INFO:tensorflow:loss = 156441.58, step = 9101 (2.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.2611\n",
      "INFO:tensorflow:loss = 155362.72, step = 9201 (2.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.776\n",
      "INFO:tensorflow:loss = 175702.78, step = 9301 (2.010 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.6145\n",
      "INFO:tensorflow:loss = 154733.97, step = 9401 (2.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.083\n",
      "INFO:tensorflow:loss = 165865.02, step = 9501 (2.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.8753\n",
      "INFO:tensorflow:loss = 182730.03, step = 9601 (2.005 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.2393\n",
      "INFO:tensorflow:loss = 171240.84, step = 9701 (2.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.6842\n",
      "INFO:tensorflow:loss = 144878.33, step = 9801 (1.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.554\n",
      "INFO:tensorflow:loss = 181773.05, step = 9901 (2.019 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.5295\n",
      "INFO:tensorflow:loss = 133698.97, step = 10001 (2.020 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.3325\n",
      "INFO:tensorflow:loss = 147192.6, step = 10101 (2.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.2144\n",
      "INFO:tensorflow:loss = 151833.19, step = 10201 (2.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.5051\n",
      "INFO:tensorflow:loss = 148920.89, step = 10301 (1.980 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.7567\n",
      "INFO:tensorflow:loss = 156835.9, step = 10401 (2.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.3934\n",
      "INFO:tensorflow:loss = 145279.27, step = 10501 (2.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.0918\n",
      "INFO:tensorflow:loss = 164515.06, step = 10601 (2.035 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.1\n",
      "INFO:tensorflow:loss = 166758.22, step = 10701 (2.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.2813\n",
      "INFO:tensorflow:loss = 189033.4, step = 10801 (2.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.7247\n",
      "INFO:tensorflow:loss = 151832.12, step = 10901 (2.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.0501\n",
      "INFO:tensorflow:loss = 150474.33, step = 11001 (1.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.8388\n",
      "INFO:tensorflow:loss = 157473.17, step = 11101 (1.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.3018\n",
      "INFO:tensorflow:loss = 162264.61, step = 11201 (1.988 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.813\n",
      "INFO:tensorflow:loss = 132023.25, step = 11301 (1.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.2513\n",
      "INFO:tensorflow:loss = 186174.95, step = 11401 (1.991 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.813\n",
      "INFO:tensorflow:loss = 167382.1, step = 11501 (1.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.1253\n",
      "INFO:tensorflow:loss = 156907.73, step = 11601 (1.996 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.1884\n",
      "INFO:tensorflow:loss = 177356.52, step = 11701 (2.034 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.852\n",
      "INFO:tensorflow:loss = 151054.67, step = 11801 (2.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.975\n",
      "INFO:tensorflow:loss = 148969.47, step = 11901 (2.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.4966\n",
      "INFO:tensorflow:loss = 165825.7, step = 12001 (2.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.208\n",
      "INFO:tensorflow:loss = 159543.94, step = 12101 (2.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.0367\n",
      "INFO:tensorflow:loss = 170706.8, step = 12201 (2.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.7805\n",
      "INFO:tensorflow:loss = 145902.31, step = 12301 (2.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.8295\n",
      "INFO:tensorflow:loss = 149821.81, step = 12401 (2.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.6636\n",
      "INFO:tensorflow:loss = 139315.38, step = 12501 (2.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.4496\n",
      "INFO:tensorflow:loss = 181451.42, step = 12601 (2.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.5295\n",
      "INFO:tensorflow:loss = 161714.73, step = 12701 (2.019 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.2144\n",
      "INFO:tensorflow:loss = 134047.88, step = 12801 (2.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.8011\n",
      "INFO:tensorflow:loss = 168691.3, step = 12901 (2.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.7555\n",
      "INFO:tensorflow:loss = 151442.22, step = 13001 (2.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.0045\n",
      "INFO:tensorflow:loss = 142911.33, step = 13101 (2.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.2144\n",
      "INFO:tensorflow:loss = 155857.7, step = 13201 (2.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.8281\n",
      "INFO:tensorflow:loss = 160503.05, step = 13301 (2.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.05\n",
      "INFO:tensorflow:loss = 145257.12, step = 13401 (1.998 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.1505\n",
      "INFO:tensorflow:loss = 160469.3, step = 13501 (1.995 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.975\n",
      "INFO:tensorflow:loss = 158313.77, step = 13601 (2.001 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.3018\n",
      "INFO:tensorflow:loss = 178437.06, step = 13701 (1.987 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.5295\n",
      "INFO:tensorflow:loss = 169774.42, step = 13801 (2.020 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.0769\n",
      "INFO:tensorflow:loss = 168030.81, step = 13901 (2.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.9716\n",
      "INFO:tensorflow:loss = 165100.0, step = 14001 (2.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.9035\n",
      "INFO:tensorflow:loss = 151211.42, step = 14101 (2.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.975\n",
      "INFO:tensorflow:loss = 152101.39, step = 14201 (2.000 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.9002\n",
      "INFO:tensorflow:loss = 146898.64, step = 14301 (2.004 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.0918\n",
      "INFO:tensorflow:loss = 162150.48, step = 14401 (2.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.6032\n",
      "INFO:tensorflow:loss = 134959.16, step = 14501 (2.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.3607\n",
      "INFO:tensorflow:loss = 152524.19, step = 14601 (2.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.2854\n",
      "INFO:tensorflow:loss = 161238.86, step = 14701 (2.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.1\n",
      "INFO:tensorflow:loss = 152439.03, step = 14801 (2.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.6329\n",
      "INFO:tensorflow:loss = 138793.73, step = 14901 (1.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.6381\n",
      "INFO:tensorflow:loss = 170219.72, step = 15001 (2.056 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 48.3793\n",
      "INFO:tensorflow:loss = 139738.2, step = 15101 (2.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.456\n",
      "INFO:tensorflow:loss = 156890.0, step = 15201 (2.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.6621\n",
      "INFO:tensorflow:loss = 153199.52, step = 15301 (2.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.0307\n",
      "INFO:tensorflow:loss = 153206.05, step = 15401 (2.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.8823\n",
      "INFO:tensorflow:loss = 146254.62, step = 15501 (2.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.9684\n",
      "INFO:tensorflow:loss = 181576.92, step = 15601 (1.961 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.8011\n",
      "INFO:tensorflow:loss = 161736.88, step = 15701 (2.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.554\n",
      "INFO:tensorflow:loss = 164578.77, step = 15801 (2.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.6524\n",
      "INFO:tensorflow:loss = 161756.28, step = 15901 (2.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.505\n",
      "INFO:tensorflow:loss = 144582.03, step = 16001 (2.020 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.8505\n",
      "INFO:tensorflow:loss = 159497.88, step = 16101 (2.006 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.7265\n",
      "INFO:tensorflow:loss = 166053.25, step = 16201 (2.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.4959\n",
      "INFO:tensorflow:loss = 142196.17, step = 16301 (2.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.554\n",
      "INFO:tensorflow:loss = 160212.64, step = 16401 (2.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.3097\n",
      "INFO:tensorflow:loss = 149866.72, step = 16501 (2.028 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.8759\n",
      "INFO:tensorflow:loss = 150832.5, step = 16601 (2.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.2859\n",
      "INFO:tensorflow:loss = 160247.39, step = 16701 (2.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.776\n",
      "INFO:tensorflow:loss = 169107.23, step = 16801 (2.010 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.5817\n",
      "INFO:tensorflow:loss = 173635.12, step = 16901 (1.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.0501\n",
      "INFO:tensorflow:loss = 167858.6, step = 17001 (1.998 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.3525\n",
      "INFO:tensorflow:loss = 152048.02, step = 17101 (1.986 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.4261\n",
      "INFO:tensorflow:loss = 135581.06, step = 17201 (2.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.3822\n",
      "INFO:tensorflow:loss = 165655.16, step = 17301 (2.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.6032\n",
      "INFO:tensorflow:loss = 155312.61, step = 17401 (2.016 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.8927\n",
      "INFO:tensorflow:loss = 158554.12, step = 17501 (2.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.2368\n",
      "INFO:tensorflow:loss = 161756.81, step = 17601 (2.031 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.852\n",
      "INFO:tensorflow:loss = 171497.34, step = 17701 (2.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.2535\n",
      "INFO:tensorflow:loss = 157946.38, step = 17801 (2.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.7512\n",
      "INFO:tensorflow:loss = 149511.58, step = 17901 (2.010 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.083\n",
      "INFO:tensorflow:loss = 161358.48, step = 18001 (2.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.4262\n",
      "INFO:tensorflow:loss = 148568.75, step = 18101 (2.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.1464\n",
      "INFO:tensorflow:loss = 145825.62, step = 18201 (2.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.1253\n",
      "INFO:tensorflow:loss = 163803.16, step = 18301 (1.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.554\n",
      "INFO:tensorflow:loss = 151376.8, step = 18401 (2.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.0146\n",
      "INFO:tensorflow:loss = 161453.64, step = 18501 (2.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.2126\n",
      "INFO:tensorflow:loss = 169139.1, step = 18601 (2.032 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.8043\n",
      "INFO:tensorflow:loss = 146245.25, step = 18701 (2.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.9165\n",
      "INFO:tensorflow:loss = 166119.9, step = 18801 (1.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.3793\n",
      "INFO:tensorflow:loss = 142284.08, step = 18901 (2.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.2765\n",
      "INFO:tensorflow:loss = 158091.48, step = 19001 (1.989 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.7875\n",
      "INFO:tensorflow:loss = 144974.89, step = 19101 (2.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.7071\n",
      "INFO:tensorflow:loss = 149165.47, step = 19201 (2.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.5561\n",
      "INFO:tensorflow:loss = 157583.05, step = 19301 (1.978 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.6073\n",
      "INFO:tensorflow:loss = 157725.56, step = 19401 (1.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.3525\n",
      "INFO:tensorflow:loss = 141427.75, step = 19501 (1.987 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.7946\n",
      "INFO:tensorflow:loss = 131543.97, step = 19601 (2.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.1698\n",
      "INFO:tensorflow:loss = 144282.38, step = 19701 (2.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.1928\n",
      "INFO:tensorflow:loss = 180819.06, step = 19801 (2.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.3261\n",
      "INFO:tensorflow:loss = 146009.1, step = 19901 (2.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.5511\n",
      "INFO:tensorflow:loss = 131130.28, step = 20001 (2.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.3392\n",
      "INFO:tensorflow:loss = 148005.83, step = 20101 (2.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.2321\n",
      "INFO:tensorflow:loss = 158863.08, step = 20201 (2.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.1696\n",
      "INFO:tensorflow:loss = 183154.95, step = 20301 (2.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.0588\n",
      "INFO:tensorflow:loss = 173920.06, step = 20401 (2.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.2367\n",
      "INFO:tensorflow:loss = 157439.77, step = 20501 (2.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.7716\n",
      "INFO:tensorflow:loss = 168699.56, step = 20601 (2.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.0663\n",
      "INFO:tensorflow:loss = 171698.83, step = 20701 (2.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.5673\n",
      "INFO:tensorflow:loss = 131515.72, step = 20801 (2.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.1001\n",
      "INFO:tensorflow:loss = 148150.36, step = 20901 (2.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.3392\n",
      "INFO:tensorflow:loss = 169093.72, step = 21001 (2.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.8759\n",
      "INFO:tensorflow:loss = 160744.6, step = 21101 (2.046 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.1159\n",
      "INFO:tensorflow:loss = 139653.69, step = 21201 (2.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.975\n",
      "INFO:tensorflow:loss = 154162.66, step = 21301 (2.001 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.9002\n",
      "INFO:tensorflow:loss = 146675.53, step = 21401 (2.004 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.7512\n",
      "INFO:tensorflow:loss = 129463.9, step = 21501 (2.010 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.334\n",
      "INFO:tensorflow:loss = 165199.39, step = 21601 (2.027 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.5561\n",
      "INFO:tensorflow:loss = 147093.92, step = 21701 (1.978 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.6842\n",
      "INFO:tensorflow:loss = 139470.78, step = 21801 (1.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.3018\n",
      "INFO:tensorflow:loss = 152495.38, step = 21901 (1.988 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.7099\n",
      "INFO:tensorflow:loss = 154736.67, step = 22001 (1.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.0918\n",
      "INFO:tensorflow:loss = 139127.02, step = 22101 (2.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.5201\n",
      "INFO:tensorflow:loss = 161956.0, step = 22201 (2.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.6771\n",
      "INFO:tensorflow:loss = 164221.03, step = 22301 (2.013 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.852\n",
      "INFO:tensorflow:loss = 171270.12, step = 22401 (2.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.1042\n",
      "INFO:tensorflow:loss = 150031.03, step = 22501 (2.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.6278\n",
      "INFO:tensorflow:loss = 153690.95, step = 22601 (2.013 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.5561\n",
      "INFO:tensorflow:loss = 142620.42, step = 22701 (1.978 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.1253\n",
      "INFO:tensorflow:loss = 165452.06, step = 22801 (1.996 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.7567\n",
      "INFO:tensorflow:loss = 157132.25, step = 22901 (2.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.4315\n",
      "INFO:tensorflow:loss = 157923.84, step = 23001 (2.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.5964\n",
      "INFO:tensorflow:loss = 170178.6, step = 23101 (2.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.7265\n",
      "INFO:tensorflow:loss = 156907.97, step = 23201 (2.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.3018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 158495.14, step = 23301 (1.987 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.6524\n",
      "INFO:tensorflow:loss = 178494.39, step = 23401 (2.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 50\n",
      "INFO:tensorflow:loss = 144720.81, step = 23501 (2.000 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.0769\n",
      "INFO:tensorflow:loss = 165223.75, step = 23601 (2.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.5786\n",
      "INFO:tensorflow:loss = 159912.17, step = 23701 (2.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.7329\n",
      "INFO:tensorflow:loss = 165833.47, step = 23801 (2.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.7329\n",
      "INFO:tensorflow:loss = 154753.6, step = 23901 (2.053 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24000 into trained_models/reg-model-02\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-22-11:34:52\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from trained_models/reg-model-02\\model.ckpt-24000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-215-c36158186bab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".......................................\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_config\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meval_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mtime_end\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutcnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".......................................\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramLanguageCore\\Python\\anaconda351\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(estimator, train_spec, eval_spec)\u001b[0m\n\u001b[0;32m    469\u001b[0m         '(with task id 0).  Given task id {}'.format(config.task_id))\n\u001b[0;32m    470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramLanguageCore\\Python\\anaconda351\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    608\u001b[0m         config.task_type != run_config_lib.TaskType.EVALUATOR):\n\u001b[0;32m    609\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Running training and evaluation locally (non-distributed).'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_local\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m     \u001b[1;31m# Distributed case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramLanguageCore\\Python\\anaconda351\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\u001b[0m in \u001b[0;36mrun_local\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[0mmax_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_hooks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m         saving_listeners=saving_listeners)\n\u001b[0m\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m     eval_result = listener_for_eval.eval_result or _EvalResult(\n",
      "\u001b[1;32mD:\\ProgramLanguageCore\\Python\\anaconda351\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramLanguageCore\\Python\\anaconda351\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1205\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1206\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1207\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1209\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramLanguageCore\\Python\\anaconda351\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1239\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[0;32m   1240\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1241\u001b[1;33m                                              saving_listeners)\n\u001b[0m\u001b[0;32m   1242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramLanguageCore\\Python\\anaconda351\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[1;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[0;32m   1469\u001b[0m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1470\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1471\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1472\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramLanguageCore\\Python\\anaconda351\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, exception_type, exception_value, traceback)\u001b[0m\n\u001b[0;32m    781\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexception_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mexception_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 783\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_close_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexception_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    784\u001b[0m     \u001b[1;31m# __exit__ should return True to suppress an exception.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mexception_type\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramLanguageCore\\Python\\anaconda351\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m_close_internal\u001b[1;34m(self, exception_type)\u001b[0m\n\u001b[0;32m    814\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 816\u001b[1;33m           \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_sess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    817\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramLanguageCore\\Python\\anaconda351\\lib\\site-packages\\tensorflow\\python\\training\\basic_session_run_hooks.py\u001b[0m in \u001b[0;36mend\u001b[1;34m(self, session)\u001b[0m\n\u001b[0;32m    586\u001b[0m     \u001b[0mlast_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_global_step_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlast_step\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_triggered_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_listeners\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m       \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramLanguageCore\\Python\\anaconda351\\lib\\site-packages\\tensorflow\\python\\training\\basic_session_run_hooks.py\u001b[0m in \u001b[0;36m_save\u001b[1;34m(self, session, step)\u001b[0m\n\u001b[0;32m    605\u001b[0m     \u001b[0mshould_stop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_listeners\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m       \u001b[1;32mif\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m         logging.info(\n\u001b[0;32m    609\u001b[0m             \u001b[1;34m\"A CheckpointSaverListener requested that training be stopped. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramLanguageCore\\Python\\anaconda351\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\u001b[0m in \u001b[0;36mafter_save\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    515\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_trigger_for_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobal_step_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobal_step_value\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# updates self.eval_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_continuous_eval_listener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m         logging.info('Exiting evaluation, as requested by '\n",
      "\u001b[1;32mD:\\ProgramLanguageCore\\Python\\anaconda351\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\u001b[0m in \u001b[0;36m_evaluate\u001b[1;34m(self, global_step_value)\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_last_triggered_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobal_step_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m     self.eval_result, self.export_results = (\n\u001b[1;32m--> 537\u001b[1;33m         self._evaluator.evaluate_and_export())\n\u001b[0m\u001b[0;32m    538\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0m_EvalStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEVALUATED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m       \u001b[1;31m#  This is unexpected; should never happen.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramLanguageCore\\Python\\anaconda351\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\u001b[0m in \u001b[0;36mevaluate_and_export\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    910\u001b[0m           \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eval_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m           \u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlatest_ckpt_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m           hooks=self._eval_spec.hooks)\n\u001b[0m\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;31m# _EvalResult validates the metrics.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramLanguageCore\\Python\\anaconda351\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, input_fn, steps, hooks, checkpoint_path, name)\u001b[0m\n\u001b[0;32m    476\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 478\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_convert_eval_steps_to_hooks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramLanguageCore\\Python\\anaconda351\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_evaluate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m             \u001b[0meval_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[0mall_hooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mall_hooks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 467\u001b[1;33m             output_dir=self.eval_dir(name))\n\u001b[0m\u001b[0;32m    468\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramLanguageCore\\Python\\anaconda351\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_evaluate_run\u001b[1;34m(self, checkpoint_path, scaffold, update_op, eval_dict, all_hooks, output_dir)\u001b[0m\n\u001b[0;32m   1589\u001b[0m         \u001b[0mfinal_ops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1590\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mall_hooks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1591\u001b[1;33m         config=self._session_config)\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m     \u001b[0mcurrent_global_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGLOBAL_STEP\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramLanguageCore\\Python\\anaconda351\\lib\\site-packages\\tensorflow\\python\\training\\evaluation.py\u001b[0m in \u001b[0;36m_evaluate_once\u001b[1;34m(checkpoint_path, master, scaffold, eval_ops, feed_dict, final_ops, final_ops_feed_dict, hooks, config)\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meval_ops\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m         \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_ops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m   logging.info('Finished evaluation at ' + time.strftime('%Y-%m-%d-%H:%M:%S',\n",
      "\u001b[1;32mD:\\ProgramLanguageCore\\Python\\anaconda351\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    669\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m                           run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m    672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramLanguageCore\\Python\\anaconda351\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1154\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1156\u001b[1;33m                               run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m   1157\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1158\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[1;32mD:\\ProgramLanguageCore\\Python\\anaconda351\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1238\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1239\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1240\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1241\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1242\u001b[0m       \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramLanguageCore\\Python\\anaconda351\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1310\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1312\u001b[1;33m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramLanguageCore\\Python\\anaconda351\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1076\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1077\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramLanguageCore\\Python\\anaconda351\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramLanguageCore\\Python\\anaconda351\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramLanguageCore\\Python\\anaconda351\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramLanguageCore\\Python\\anaconda351\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramLanguageCore\\Python\\anaconda351\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramLanguageCore\\Python\\anaconda351\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if not RESUME_TRAINING:\n",
    "    print(\"Removing previous artifacts...\")\n",
    "    shutil.rmtree(model_dir, ignore_errors=True)\n",
    "else:\n",
    "    print(\"Resuming training...\") \n",
    "time_start = datetime.utcnow() \n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "print(\"Experiment started at {}\".format(time_start.strftime(\"%H:%M:%S\")))\n",
    "print(\".......................................\") \n",
    "estimator=create_estimator(run_config,hparams)\n",
    "tf.estimator.train_and_evaluate(estimator=estimator,train_spec=train_spec,eval_spec=eval_spec)\n",
    "time_end=datetime.utcnow()\n",
    "print(\".......................................\")\n",
    "print(\"Experiment finished at {}\".format(time_end.strftime(\"%H:%M:%S\")))\n",
    "print(\"\")\n",
    "time_elapsed = time_end - time_start\n",
    "print(\"Experiment elapsed time: {} seconds\".format(time_elapsed.total_seconds()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-22-11:38:07\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from trained_models/reg-model-02\\model.ckpt-24000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-22-11:38:07\n",
      "INFO:tensorflow:Saving dict for global step 24000: average_loss = 372.95963, global_step = 24000, label/mean = 1.7754534, loss = 186479.81, prediction/mean = 0.41338992\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 24000: trained_models/reg-model-02\\model.ckpt-24000\n",
      "\n",
      "############################################################################################\n",
      "# Train RMSE: 19.31216 - {'average_loss': 372.95963, 'label/mean': 1.7754534, 'loss': 186479.81, 'prediction/mean': 0.41338992, 'global_step': 24000}\n",
      "############################################################################################\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-22-11:38:08\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from trained_models/reg-model-02\\model.ckpt-24000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-22-11:38:09\n",
      "INFO:tensorflow:Saving dict for global step 24000: average_loss = 269.2687, global_step = 24000, label/mean = -0.211853, loss = 134634.36, prediction/mean = 0.37805882\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 24000: trained_models/reg-model-02\\model.ckpt-24000\n",
      "\n",
      "############################################################################################\n",
      "# Valid RMSE: 16.40941 - {'average_loss': 269.2687, 'label/mean': -0.211853, 'loss': 134634.36, 'prediction/mean': 0.37805882, 'global_step': 24000}\n",
      "############################################################################################\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-22-11:38:09\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from trained_models/reg-model-02\\model.ckpt-24000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-22-11:38:09\n",
      "INFO:tensorflow:Saving dict for global step 24000: average_loss = 320.5348, global_step = 24000, label/mean = 1.7207786, loss = 160267.39, prediction/mean = 0.38636225\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 24000: trained_models/reg-model-02\\model.ckpt-24000\n",
      "\n",
      "############################################################################################\n",
      "# Test RMSE: 17.90349 - {'average_loss': 320.5348, 'label/mean': 1.7207786, 'loss': 160267.39, 'prediction/mean': 0.38636225, 'global_step': 24000}\n",
      "############################################################################################\n"
     ]
    }
   ],
   "source": [
    "train_results = estimator.evaluate(input_fn=train_input_fn, steps=1)\n",
    "train_rmse = round(math.sqrt(train_results[\"average_loss\"]),5)\n",
    "print()\n",
    "print(\"############################################################################################\")\n",
    "print(\"# Train RMSE: {} - {}\".format(train_rmse, train_results))\n",
    "print(\"############################################################################################\")\n",
    "\n",
    "valid_results = estimator.evaluate(input_fn=valid_input_fn, steps=1)\n",
    "valid_rmse = round(math.sqrt(valid_results[\"average_loss\"]),5)\n",
    "print()\n",
    "print(\"############################################################################################\")\n",
    "print(\"# Valid RMSE: {} - {}\".format(valid_rmse,valid_results))\n",
    "print(\"############################################################################################\")\n",
    "\n",
    "test_results = estimator.evaluate(input_fn=test_input_fn, steps=1)\n",
    "test_rmse = round(math.sqrt(test_results[\"average_loss\"]),5)\n",
    "print()\n",
    "print(\"############################################################################################\")\n",
    "print(\"# Test RMSE: {} - {}\".format(test_rmse, test_results))\n",
    "print(\"############################################################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from trained_models/reg-model-02\\model.ckpt-24000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "\n",
      "Predicted Values: [0.99982125, -0.011527352, -0.20706996, 0.13667259, 0.20198691]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "predictions = estimator.predict(input_fn=predict_input_fn)\n",
    "values = list(map(lambda item: item[\"predictions\"][0],list(itertools.islice(predictions, 5))))\n",
    "print()\n",
    "print(\"Predicted Values: {}\".format(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: 'trained_models/reg-model-02/export/estimate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-225-e51cef904576>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mexport_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_dir\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m\"/export/estimate\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0msaved_model_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexport_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 系统找不到指定的路径。: 'trained_models/reg-model-02/export/estimate'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "export_dir = model_dir +\"/export/estimate\"\n",
    "\n",
    "saved_model_dir = export_dir + \"/\" + os.listdir(path=export_dir)[-1] \n",
    "\n",
    "print(saved_model_dir)\n",
    "\n",
    "predictor_fn = tf.contrib.predictor.from_saved_model( export_dir = saved_model_dir, signature_def_key=\"predict\")\n",
    "\n",
    "output = predictor_fn({'csv_rows': [\"0.5,1,ax01,bx02\", \"-0.5,-1,ax02,bx02\"]})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\my_proj\\\\fog_recognition\\\\recognition_pre_fog_tf\\\\notebook'"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
